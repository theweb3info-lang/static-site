# 全球最安全的AI公司，它的安全负责人跑了

![AI安全](https://images.pexels.com/photos/8386440/pexels-photo-8386440.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=2)

全球估值最高的AI公司之一，它的安全负责人跑了。

跑之前留了一句话：

**"世界危在旦夕。"**（The world is in peril.）

2026年2月9日，Mrinank Sharma 在社交平台X上发布了他的辞职信。他的最后一天，是周一。

辞职信在几天内获得了近**100万次浏览**。（据 Forbes 报道）

看到这条新闻，人们的反应大概分三种：

**第一种：** "又一个蹭热度的，至于吗？"

**第二种：** "这人谁啊？AI安全又是个啥？"

**第三种：** 后背一凉——"等等，如果连造AI的人都害怕了，那我们呢？"

---

## 先说说背景：Anthropic 是谁？

如果你用过 Claude，你就用过 Anthropic 的产品。

Anthropic 是一家美国AI公司，2021年成立。创始团队从 OpenAI 出走，理由是——觉得 OpenAI 不够重视安全。

没错，它**就是因为"安全"两个字诞生的**。

2026年2月，Anthropic 完成了 G 轮融资，筹集了**300亿美元**，估值达到了**3800亿美元**。（据 Anthropic 官方公告）

3800亿美元什么概念？

差不多等于一个可口可乐。

它是目前全球估值最高的AI初创公司之一。

而 Mrinank Sharma，就是这家公司的**AI安全保障研究团队负责人**（head of safeguards research team）。

---

## "AI安全研究"到底在干啥？

很多人听到"AI安全"，第一反应是：防止机器人造反？

没那么科幻。

你可以这样理解——

如果AI是一辆越来越快的赛车，AI安全研究员就是**负责装刹车和安全带的人**。

Sharma 的团队具体做什么？据他自己在辞职信中列举：

- 研究为什么AI会**拍马屁**（学术叫法：sycophancy，就是AI不管你说啥都顺着你）
- 防范AI被用来制造**生物武器**
- 研究**AI助手如何让我们变得不再像人**

听起来是不是每一项都挺重要？

对，这就是问题所在。

**做这些事的人，走了。**

---

## 等等，先别急着划走

我知道你可能在想："又一个危言耸听的技术人员。"

但这个人不是外人。

他不是网上评论区的键盘侠，不是卖焦虑的自媒体人。

他是**从内部看到一切之后**，选择离开的人。

而且他在辞职信里写了一句非常值得玩味的话：

> "在这里的日子里，我反复看到，让我们的价值观真正主导我们的行动，有多难。"

> "即使是 Anthropic，也在不断面对压力，被迫搁置最重要的事。"

（原文：I've repeatedly seen how hard it is to truly let our values govern our actions. Even Anthropic constantly face pressures to set aside what matters most.）

来源：Sharma 在 X 上发布的辞职信（[@MrinankSharma](https://x.com/MrinankSharma/status/2020881722003583421)）

注意关键词：**"即使是 Anthropic"**。

这家公司的存在理由就是安全。

连它都扛不住商业压力。

那其他公司呢？

---

## 他不是第一个跑的

这才是最可怕的。

让我们拉一个时间线：

### 🔴 2024年5月：OpenAI "超级对齐"团队解散

OpenAI 的联合创始人 **Ilya Sutskever** 离职。

同时离职的还有"超级对齐"（Superalignment）团队负责人 **Jan Leike**。

这个团队的使命是确保超级智能AI不会失控。

Leike 离职后公开表示：在 OpenAI，"安全文化和安全流程已经让位给了光鲜亮丽的产品。"（据 CNBC 和 Vox 报道）

整个超级对齐团队随后被**解散**。

### 🔴 2026年2月：OpenAI 研究员 Zoë Hitzig 辞职

就在 Sharma 辞职的同一周。

Hitzig 在《纽约时报》发表文章，解释了她离开 OpenAI 的原因：OpenAI 开始在 ChatGPT 里**插入广告**。

她写道：

> "人们会告诉聊天机器人自己的病情、感情问题、对上帝和来世的看法。在这样的对话数据上建立广告系统，意味着可以用我们尚不了解的方式操纵用户。"

她在接受 BBC 采访时说："我对在这个行业工作感到真的很紧张。"

她把这比作社交媒体的早期——"我们已经看到了社交媒体发生了什么。"（据 BBC 报道）

### 🔴 趋势：安全人才外流

Global News 把 Sharma 的辞职称为"安全风险和伦理困境引发的**离职潮中的最新一波**"。

一个模式正在浮现：

**AI公司挖来安全研究员 → 公司规模暴涨 → 商业压力增大 → 安全让位于增长 → 安全研究员受不了，走人。**

---

## 当造刹车的人弃车而去

![AI未来](https://images.pexels.com/photos/8386367/pexels-photo-8386367.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=2)

我们重新梳理一下这件事的逻辑。

Anthropic 因为安全而生。

它刚刚融了300亿美元，估值3800亿。

它的安全负责人，在公司刚拿到史上最大AI融资之一的时候，**选择了离开**。

Sharma 说他要回英国，去**读诗歌学位**，去写作，去"练习勇敢地说话"（the practice of courageous speech）。

一个AI安全研究员，放弃硅谷顶薪，去读诗。

这不是"躺平"。

这是**用脚投票**。

他在X上的一条回复里说：离开公司之后，他才有**更多自由去公开表达观点**。

这句话才是真正的重磅。

意思是——**在里面的时候，他不能说**。

---

## 我们普通人该怎么想？

有人会说："这些都是硅谷精英的内部斗争，跟我有什么关系？"

关系大了。

你每天用的搜索引擎、社交媒体、购物推荐——背后都是AI。

AI正在决定你看到什么新闻、买什么东西、甚至怎么看待这个世界。

现在，**负责给这些系统装刹车的人，正在一个接一个地离开。**

赛车越来越快。

刹车越来越松。

而你坐在后座上。

Sharma 在辞职信中说，他担心的不只是AI本身，而是"一整套相互关联的危机"——包括生物恐怖主义、地缘政治紧张、以及AI"扭曲人性"的能力。

这不是一个技术问题。

这是一个**我们全体人类都坐在车上**的问题。

---

## 最讽刺的是什么？

2024年，OpenAI CEO Sam Altman 亲口说过：广告是"最后手段"。（据多家媒体报道）

2026年，ChatGPT 开始插广告了。

Anthropic 还在超级碗上花了大价钱打广告，**讽刺 OpenAI 放广告这件事**。（据 BBC 报道）

然后转头，自己的安全负责人也跑了。

Altman 还在X上回怼 Anthropic："用一条有误导性的广告来批评理论上的误导性广告，挺符合 Anthropic 言行不一的品牌调性的。"

AI公司们互相指责对方不安全。

可是——**谁在真正做安全？**

做安全的人都在辞职。

---

## 一个值得记住的画面

2026年2月的同一周。

一边，Anthropic 宣布完成300亿美元融资。

另一边，Anthropic 的安全负责人发布辞职信。

**钱到了，人走了。**

这个画面，可能会成为AI行业发展史上一个标志性的注脚。

---

## 最后一个问题

Sharma 走之前说，他"反复看到"价值观在商业压力面前是多么脆弱。

Hitzig 走之前说，她"曾经相信自己能帮助造AI的人提前解决问题"，但发现公司已经"不再问那些她加入时要回答的问题"。

当最懂AI的人开始害怕AI——

不是因为AI太强。

**而是因为没有人愿意停下来想一想。**

---

你觉得AI公司应该为了安全放慢脚步吗？

还是说，这就是科技发展的代价，必须有人承受？

欢迎在评论区说说你的看法。

---

> 📌 **本文信息来源：** BBC News、Forbes、Global News、Notebookcheck、CNBC、Vox、Ars Technica、Anthropic 官方公告、Sharma 及 Hitzig 在社交平台和媒体上的公开声明。
