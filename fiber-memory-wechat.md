# 游戏之神提了个疯狂建议：用 200 公里光纤当电脑内存，全世界都炸了

![cover](https://images.unsplash.com/photo-1558618666-fcd25c85cd64?w=1200&q=80)

> **如果我告诉你，一根从北京到天津的光纤，能当电脑内存用，你会怎么想？**
> 
> 是我疯了，还是科技疯了？

前几天，游戏界传奇人物 **John Carmack**（《毁灭战士》《雷神之锤》创始人，现在在研究 AI）在推特上发了条消息：

> "200 公里的光纤，延迟和 DRAM（电脑内存）差不多。"

**全网炸了。**

有人嘲笑："这家伙是不是烧坏脑子了？"  
有人困惑："光纤不是用来上网的吗？"  
少数人沉默了几秒，然后说："卧槽，他是认真的。"

**今天我们聊聊：这个看似疯狂的想法，背后藏着什么深刻的洞察。**

---

## 🤯 Part 1: 这个想法到底有多疯狂？

### 先搞清楚：什么是内存？

电脑内存（RAM）就是电脑的"工作台"。

> 想象你在做饭：
> 
> - **硬盘（SSD）** = 冰箱（存大量食材，但拿取慢）
> - **内存（RAM）** = 灶台（放正在用的食材，拿取快）
> - **CPU** = 你的手（处理食材）

**你做菜时，手要不停地从灶台拿东西。如果灶台太小，你得频繁跑去冰箱拿，效率就低了。**

**内存就是这个"灶台" —— 越大、越快，电脑运行越流畅。**

### 那光纤是干嘛的？

光纤是用来**传输数据**的 —— 比如你家的宽带，就是光纤。

> 光在光纤里跑得飞快：**每秒 20 万公里**（差不多地球赤道 5 圈）。

**但问题来了：光纤是用来"传数据"的，怎么能当"存数据"的内存？**

这就是 Carmack 的疯狂之处。

---

## 🧠 Part 2: 这个疯狂想法怎么实现？

### 原理：让光在光纤里"兜圈子"

Carmack 的想法是：**把光纤弄成一个圈，让数据（光信号）在里面不停地转。**

```
┌─────────────────────────────────┐
│   光纤延迟线存储器（简化版）     │
├─────────────────────────────────┤
│                                  │
│   ┌──────┐                       │
│   │激光器│ ──→  [光纤圈 200km]   │
│   └──────┘       ↑         ↓     │
│                  └─────────┘     │
│                 数据在这里转圈    │
│                                  │
│   光速：20 万公里/秒              │
│   200 公里 ÷ 20 万 = 1 毫秒      │
└─────────────────────────────────┘
```

**数据在光纤里转一圈，需要 1 毫秒（0.001 秒）。**

### 等等，1 毫秒 = 内存速度？

你可能要说了：

> "内存的访问速度是 100 纳秒（0.0000001 秒），1 毫秒慢了 10,000 倍！你在逗我？"

**这就是天才和普通人的区别。**

Carmack 说的"延迟差不多"，不是指**随机访问**，而是指 **AI 的顺序访问**。

---

## 🎯 Part 3: AI 不需要"随机访问"，它需要"数据流"

### 传统程序 vs. AI 程序

**传统程序（比如你打开网页）：**
```
第 1 步：读取数据[5]
第 2 步：读取数据[142]
第 3 步：读取数据[7]
↑ 跳来跳去，毫无规律
```

**AI 推理（比如 ChatGPT 生成文字）：**
```
第 1 步：读取权重[1]
第 2 步：读取权重[2]
第 3 步：读取权重[3]
↑ 顺序读取，像流水线
```

**AI 读数据就像读书 —— 从第 1 页读到第 100 页，不会跳来跳去。**

### 光纤的妙处：预加载

如果你提前知道 AI 要按顺序读数据，你可以这样做：

```
时间 0ms:  把 data[0] 放进光纤
时间 1ms:  data[0] 到了，AI 读取它
           同时 data[1] 已经在路上了
时间 2ms:  data[1] 到了，AI 读取它
           同时 data[2] 已经在路上了
...
```

**只要数据流不停，AI 根本感觉不到延迟！**

> 就像传送带：虽然每个零件从头走到尾要 1 分钟，但只要传送带不停，工人每秒都能拿到新零件。

---

## 💡 Part 4: 为什么这个想法很重要？

### 问题 1：内存太贵，太耗电

你知道数据中心（那些放服务器的大楼）最费电的是什么吗？

**不是 CPU，是内存。**

一个大型数据中心，**40% 的电费都花在给内存"续命"上**。

为什么？因为内存（DRAM）是"动态"的 —— 它每隔几毫秒就会"忘记"数据，必须不停地刷新。

> 就像你用手捧水，必须不停地合拢双手，否则水就漏了。

**光纤不一样：光在里面转，几乎不耗电。**

### 问题 2：AI 模型越来越大

ChatGPT、Claude 这些 AI 模型，参数动辄上百亿、上千亿。

**这些参数都要存在内存里，才能快速调用。**

但内存很贵：
- 16GB 内存：~500 元
- 128GB 内存：~4000 元
- 1TB 内存：天价

**如果能用便宜的光纤代替昂贵的内存，成本能降低 90%。**

### Carmack 的真实意图：挑战默认假设

其实 Carmack 不是真的要你去买 200 公里光纤。

**他在问一个更深刻的问题：**

> "我们为什么默认 AI 需要内存？  
> 为什么不能用更便宜、更省电的东西？"

这就像有人问：

> "我们为什么默认汽车要烧油？  
> 为什么不能用电？"

**20 年前，这是疯子的问题。  
今天，特斯拉市值上万亿。**

---

## 🔥 Part 5: 全网反应：嘲笑、困惑、顿悟

### 反应 1：嘲笑派

> "200 公里光纤？你是要把数据中心建在高速公路上吗？"  
> "这比特币矿机还离谱。"  
> "下一步是不是要用卫星当内存？"

**这些人的问题：把"思维实验"当成了"实施方案"。**

### 反应 2：困惑派

> "光纤不是用来上网的吗？怎么能当内存？"  
> "1 毫秒不是比 100 纳秒慢很多吗？"  
> "我没看懂。"

**这些人的问题：缺少 AI 和存储的背景知识。**

### 反应 3：顿悟派

> "等等，他说的是**延迟线存储器**！这是 1940 年代的技术！"  
> "他在挑战冯·诺依曼架构的默认假设。"  
> "天才。"

**这些人看懂了：Carmack 不是在提方案，而是在提问题。**

---

## 🚀 Part 6: 更实际的方案：闪存直连 AI 芯片

Carmack 后来说了：

> "光纤只是个思维实验。更实际的方案是：**把闪存（Flash）直接连到 AI 芯片上，跳过内存这一层。**"

### 传统 AI 服务器：

```
┌──────┐     ┌──────┐     ┌──────┐
│ SSD  │ ──→ │ 内存  │ ──→ │ GPU  │
│闪存  │     │ DRAM │     │AI芯片│
└──────┘     └──────┘     └──────┘
              ↑
           瓶颈在这里！
           耗电、昂贵
```

### Carmack 的愿景：

```
┌──────┐                  ┌──────┐
│ Flash│ ───────────────→ │ AI   │
│闪存阵列│    直接连接      │ 芯片 │
└──────┘                  └──────┘
          跳过内存！
```

**这样做的好处：**
- ✅ 成本降低 80%
- ✅ 功耗降低 60%
- ✅ 不需要 200 公里光纤

**但需要：**
- 新的接口标准（闪存 → AI 芯片）
- AI 芯片的设计改变
- 行业共识

---

## 🤔 Part 7: 这告诉我们什么？

### 1. 别被"默认假设"绑架

所有人都在优化内存速度，Carmack 问：

> "我们还需要内存吗？"

所有人都在买更快的 DRAM，Carmack 问：

> "为什么不用便宜的闪存？"

**这就是创新的起点：质疑默认。**

### 2. AI 时代需要新架构

过去 70 年，电脑都是这样设计的：

```
CPU 中心 + 内存层次（L1/L2/L3/RAM/SSD）
```

**但 AI 不需要这套！**

AI 需要的是：
- 大带宽（持续供应数据）
- 低功耗（省电）
- 大容量（存得下上千亿参数）

**传统架构满足不了，所以需要重新设计。**

### 3. "疯狂"和"天才"只差一步

Carmack 的光纤提案，听起来疯狂。

但仔细想想：
- ✅ 延迟确实和内存差不多（对 AI 来说）
- ✅ 功耗确实更低
- ✅ 成本确实更便宜

**问题只是：我们愿不愿意抛弃旧思维。**

---

## 📝 写在最后

200 公里光纤当内存，听起来像科幻小说。

**但 50 年前，有人提出"用电代替油"，也被当成笑话。**

**30 年前，有人提出"用手机上网"，也被认为是疯子。**

**10 年前，有人提出"AI 能写代码"，程序员都在嘲笑。**

**今天呢？**

Carmack 的光纤方案可能永远不会实现。

**但他提出的问题，已经在改变行业：**

- Google TPU 直接用 HBM（高带宽内存）
- Apple M 系列用统一内存
- NVIDIA 在研究 CXL（新接口标准）

**当所有人都在优化旧系统时，天才在重新设计新系统。**

**当所有人都在回答"怎么做得更好"时，天才在问"为什么要这样做"。**

---

## 💬 你怎么看？

> 如果你是 AI 芯片设计师，你会考虑 Carmack 的方案吗？  
> 还是觉得这只是个有趣的思维实验？

**欢迎在评论区聊聊你的想法。**

---

## 📊 关键数据

- **光速：** 20 万公里/秒
- **200 公里光纤延迟：** ~1 毫秒
- **DRAM 访问延迟：** ~100 纳秒
- **数据中心内存功耗占比：** ~40%
- **闪存直连潜在节省：** 成本 -80%，功耗 -60%

**参考来源：**  
Tom's Hardware, John Carmack Twitter, IEEE Spectrum

---

*文章长度：约 2,500 字 | 阅读时间：约 8 分钟*  
*适合平台：微信公众号、今日头条、网易新闻*
