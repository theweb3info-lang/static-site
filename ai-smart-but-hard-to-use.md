# AI越来越聪明，为什么用起来却越来越烦？

Google刚发布了一个新的AI模型，叫Gemini 3.1 Pro。在一个专门测试AI"智商"的考试里，它拿到了77.1%的成绩，是上一代的两倍多。

听起来很厉害对吧？但有意思的是，一大群真正在用这个模型写代码的程序员，反应却出奇一致：

**"它确实更聪明了，但用起来还是让人抓狂。"**

这不是Gemini一家的问题。这是整个AI行业正在面对的一个深层矛盾——模型越来越会考试，但人们用起来的体验，并没有同步变好。

## 一场AI界的"高考"

先说说那个测试。

ARC-AGI-2，全称"Abstraction and Reasoning Corpus"，是AI研究员François Chollet设计的一套逻辑推理测试。Chollet是Keras深度学习框架的创造者，在AI圈有着很高的声望。他创建了ARC Prize基金会，专门用这个测试来衡量AI离"通用智能"还有多远。

这个测试的设计思路很特别：它不考AI的知识储备，不考它背了多少书，而是考它能不能像人一样，面对一个**从没见过的**逻辑谜题，自己琢磨出规律来。

比如给你看几组图案变换的例子，让你推理出变换规则，然后应用到新的图案上。听起来简单？对人来说确实不难，但对AI来说曾经是噩梦级别的挑战。

Gemini 3.1 Pro在ARC-AGI-2上拿到77.1%，这意味着什么？一年前，最好的AI模型在这个测试上大概只能拿到30%左右。现在直接翻了一倍多。而且Google声称，在另一个叫APEX-Agents的基准测试中（模拟投行、咨询和法律工作的长时间复杂任务），Gemini 3.1 Pro以33.2%的成绩超过了Anthropic的Claude Opus 4.6（29.8%）和OpenAI的GPT 5.2 Codex（27.6%）。

单看数字，Google这次确实cook了一把好菜。

## 但是，真正用起来呢？

Hacker News是硅谷程序员的大本营，Gemini 3.1 Pro发布当天就冲上了头条，500多条评论。你可能以为评论区会是一片欢呼。

并不是。

一位Google前员工的评论特别有代表性。他说自己因为认识Gemini团队的人，所以一直在"默默支持"这个模型，但实际用下来：

> "Gemini在推理和代码生成上确实很强，但真正想用它干活的时候，它就掉链子了。尤其是跟Claude比，差距很明显。"

他举了几个具体的槽点：

**第一，Gemini不告诉你它在干什么。** 在VS Code编辑器里，Claude会一边思考一边告诉你"我现在在做什么、为什么这么做"。Gemini呢？它几乎把所有的"思考"都藏在后台，然后突然给你一个结果，你完全不知道它是怎么得出来的。

**第二，思考过程本身也很"水"。** 当你真的去看它的思考记录时，会发现大量类似"我现在完全沉浸在这个问题中……""我正在精心打磨答案……"这样的话。这不是在思考，这是在写作文。

**第三，容易陷入死循环。** Gemini经常在一个问题上转圈圈，不断重试同样的方法，就是走不出来。而且它很少主动问你"你是不是想要这个？"——它更喜欢自己闷头干，哪怕方向完全跑偏了。

另一位评论者说得更直白："Gemini就像Google的所有产品一样——酷炫的部分做得很好，但最后10%的打磨工作，他们永远提不起兴趣。写代码容易，做出真正赚钱的产品难。"

## "跑分"和"能用"之间，隔了一个太平洋

这种"考试第一名但实操拉胯"的现象，在AI行业其实越来越普遍。

想想看，为什么会这样？

因为基准测试和真实使用，根本就是两种完全不同的能力。

ARC-AGI测的是纯粹的逻辑推理——给你一个干净的谜题，有明确的输入和输出，让你找规则。这就像高考数学，题目是精心设计的，答案是确定的。

但真实工作场景是什么样的？需求是模糊的（"帮我改一下这个功能，你知道的就是那个"），上下文是复杂的（几十个文件、几百个依赖），反馈是即时的（用户说"不对，我不是这个意思"），而且需要持续的沟通和协作。

一个有趣的对比：在HN讨论中，有人引用了APEX-Agents的数据，说Gemini 3.1 Pro在这个更贴近实际工作的测试中也拿了第一。但马上就有人回复：

> "基准测试在我的经验里基本上毫无意义。如果跑分说了算，那些中国的开源模型早就该碾压一切了。但实际用起来呢？只是'还行'而已。"

这话可能有点极端，但确实点出了一个问题：我们衡量AI"智能"的方式，和我们实际需要AI做的事情，正在渐行渐远。

## 有一群人已经想明白了

有趣的是，就在Gemini 3.1 Pro发布的同一天，Hacker News上还有另一篇热文，标题叫《AI不是你的同事，是你的外骨骼》。

文章来自一家叫Kasava的公司。他们的核心观点是：整个行业对AI的定位搞错了。

大家都在追求"AI Agent"——一个能自己干活、自己做决定、不需要人插手的自动化员工。但真正在AI上赚到钱的公司，用的是完全不同的思路：把AI当成人类能力的放大器，而不是替代品。

他们举了一个很形象的类比：外骨骼。

福特汽车在全球15个工厂部署了EksoVest外骨骼。工人还是那些工人，活还是那些活——每天要把手举过头顶4600次。但外骨骼给每条手臂提供了5-15磅的辅助力。结果？使用外骨骼的生产线，工伤率下降了83%。

美国军方的Sarcos Guardian XO外骨骼能提供20:1的力量放大——100磅的东西背起来只像5磅。士兵还是士兵，但能力被放大了20倍。

斯坦福大学2020年的研究显示，他们的踝关节外骨骼能让跑步的能量消耗降低15%，理论上能让马拉松选手的速度提高约10%。

发现规律了吗？**外骨骼从来不替代人。它不替你搬箱子、不替你跑马拉松。它只是让你做同样的事情时，能做得更多、更久、更不容易受伤。**

Kasava认为，AI应该走同样的路。不要造一个"AI员工"让它自己去想该干什么，而是造一个"AI外骨骼"，让人类在做决策时拥有超人的信息处理能力。

## Anthropic悄悄做对了一件事

说到这里，不得不提一下Anthropic——Claude系列模型的母公司。

在HN的讨论中，有一条评论引起了广泛共鸣：

> "2024年中，Anthropic做了一个深思熟虑的决定：不再追求跑分，转而专注于实际价值。当时很多人持怀疑态度，但事后证明，这是一个极有远见的决定。"

这是什么意思？就是说，当Google和OpenAI在各种基准测试上你追我赶的时候，Anthropic选择了一条不同的路：与其让模型在考试中多拿几分，不如让模型在真实场景中更好用。

体现在哪里？Claude会主动告诉你它在想什么；遇到不确定的地方会停下来问你；编辑文件时会用合适的工具而不是发明自己的方法；不会在一个问题上死磕到底，而是会及时调整方向。

这些东西，没有任何一个基准测试会去衡量。但它们就是让一个AI从"很聪明"变成"很好用"的关键。

用开发者社区的话说："Gemini是那个每次考试都第一名但不会做实验的学霸，Claude是那个成绩可能差几分但你做项目一定想跟他组队的同学。"

## 一个正在消失的传统

HN讨论中还有一个特别有意思的观点，来自一位对"透明性"特别在意的开发者：

> "Web有一个美好的传统：浏览器同时也是调试器。从几十年前的'查看源代码'，到Firebug启发的现代浏览器控制台，一切都是可见的、可检查的。现在呢？大量的'思考'发生在一层帷幕后面。我的Agent编译了什么样的prompt发出去了？完整的输出是什么样的？这些我都看不到。"

这个观点触及了一个更深层的问题：**AI越来越强大的同时，也越来越不透明了。**

过去的软件，你可以查看源代码，可以用调试器一步步跟踪。出了bug，你能找到原因。但现在的AI呢？它为什么做出这个决定？为什么忽然改了方向？为什么一直在同一个地方转圈？你不知道。它也不告诉你。

这不只是技术问题，这是信任问题。当你把越来越重要的工作交给一个你无法理解的系统，你其实是在做一个巨大的信任投注。

## 所以，AI到底该往哪走？

回到开头的问题：Gemini 3.1 Pro是不是一个好模型？

从"智商"的角度，毫无疑问是。ARC-AGI-2得分翻倍，多项基准测试领先，推理能力大幅提升。如果AI界有高考，它就是今年的状元。

但从"好不好用"的角度？评价就复杂多了。光有脑子不够，还得会跟人协作、会沟通、会在对的时候停下来问一句"你确定吗？"。

2026年的AI行业，正站在一个有意思的十字路口。

一条路是继续卷"智商"——追求更高的推理分数、更好的考试成绩、更惊艳的Demo。这条路的终点可能是一个超级聪明但你不知道怎么跟它相处的"天才"。

另一条路是开始卷"情商"——让AI更好地理解人的意图、更透明地展示自己的思考过程、更恰当地知道什么时候该自己干什么时候该问人。这条路的终点是一个也许没那么聪明但你愿意天天跟它一起干活的"搭档"。

当然，最好的结果是两条路都走。但如果只能选一条，我赌后者。

因为历史一次又一次告诉我们：**最后赢的产品，从来不是最聪明的那个，而是最好用的那个。**

VHS打败了画质更好的Betamax。Windows打败了技术更优的Mac OS（至少在PC时代是这样）。Google打败了搜索结果更全的Yahoo。iPhone打败了功能更多的诺基亚。

每一次，赢家都是那个"用起来更舒服"的选择。

AI也不会例外。🤖

---

*本文数据来源：Google AI Blog（2026年2月19日）、Hacker News社区讨论、ARC Prize Foundation、Kasava.dev。文中引用的用户评论已做适当翻译和编辑。*
